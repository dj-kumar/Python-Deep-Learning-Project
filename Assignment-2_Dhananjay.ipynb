{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cd963f-1f34-4f9d-ac14-3178d5988a15",
   "metadata": {},
   "source": [
    "# Assignment-2 : Keras Machine Learning Model #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07227e6b-a91c-42db-89bf-22ca915d241a",
   "metadata": {},
   "source": [
    "### Submitted by Dhananjay Kumar : 135297208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068850b4-0c17-45b8-a46d-a9da04997316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb47ece-4e93-40a3-9ce4-ddd4e442e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sample dataset of text\n",
    "\n",
    "mytext = ['can I order pizza', 'can we go to the mall', 'can I drive', 'yes lets order pizza', 'yes in the evening', 'yes you can drive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5131871-8083-43c1-8551-c35a1f60ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the class labels for Dataset\n",
    "\n",
    "mytextlabels = array([1, 1, 1, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2817e5f3-091b-4481-87d7-3a3d862f823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 9, 22, 4], [10, 7, 28, 29, 8, 23], [10, 9, 11], [10, 14, 22, 4], [10, 26, 8, 8], [10, 29, 10, 11]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the test dataset using one_hot encoding\n",
    "\n",
    "textvocabs = 30\n",
    "encodtext = [one_hot(i,textvocabs) for i in mytext]\n",
    "print(encodtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de740ee",
   "metadata": {},
   "source": [
    "### <U> Explanation: </U>\n",
    "Deep learning methods cannot work with categorical data directly. Categorical data must be converted into numbers in order to work on them. That's why we used one hot encoding to convert the categorical values to integer values. One hot encoding converts the categorical value into binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9d580f-30cd-4c6b-a1d3-1d87d9795e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 10  9 22  4]\n",
      " [ 0 10  7 28 29  8 23]\n",
      " [ 0  0  0  0 10  9 11]\n",
      " [ 0  0  0 10 14 22  4]\n",
      " [ 0  0  0 10 26  8  8]\n",
      " [ 0  0  0 10 29 10 11]]\n"
     ]
    }
   ],
   "source": [
    "# Padding the encoded dataset to a max length of 7\n",
    "\n",
    "length = 7\n",
    "padmytext = pad_sequences(encodtext, maxlen=length,padding='pre')\n",
    "print(padmytext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec5f123-3e72-48c1-92ba-a01e9de27365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6853 - accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.8333\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6823 - accuracy: 0.8333\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6809 - accuracy: 0.8333\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6794 - accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6780 - accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6765 - accuracy: 0.8333\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6751 - accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6736 - accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.8333\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6693 - accuracy: 0.8333\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6678 - accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6664 - accuracy: 0.8333\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6649 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6635 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6620 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6561 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6531 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6515 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6500 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6485 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6469 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6453 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6438 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fdc5d720d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a machine learning model\n",
    "\n",
    "mymodel = Sequential()\n",
    "mymodel.add(Embedding(textvocabs, 8, input_length=length))\n",
    "mymodel.add(Flatten())\n",
    "mymodel.add(Dense(1, activation = 'sigmoid'))\n",
    "mymodel.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mymodel.fit(padmytext,mytextlabels, epochs=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89c02a",
   "metadata": {},
   "source": [
    "### <U> Findings from the model </U>\n",
    "We can see that the loss is 64% and accuracy is 100%. Ideal model should have the lowest loss and highest accuracy (Closer to 1.0 or 100%). Based on above results, we can say our model is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "734c43bb-432d-486b-8342-303c66a7f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 9, 10, 1, 27], [10, 29, 1, 27]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a prediction model\n",
    "\n",
    "predict_text =['Yes I can speak German', 'Can you speak German']\n",
    "\n",
    "# Encoding the prediction text using one_hot\n",
    "\n",
    "vocab_text = 30\n",
    "encod_ptext= [one_hot(d, vocab_text) for d in predict_text]\n",
    "print(encod_ptext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64472efe-9574-425f-9981-8f99124cc63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 10  9 10  1 27]\n",
      " [ 0  0  0 10 29  1 27]]\n"
     ]
    }
   ],
   "source": [
    "# Padding the the encoded_text\n",
    "\n",
    "max_length = 7\n",
    "pred_paded = pad_sequences(encod_ptext, maxlen= max_length, padding='pre')\n",
    "print(pred_paded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0b2759-4550-4121-be1e-0bfecb4e5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 193ms/step\n",
      "[[0.50589156]\n",
      " [0.47289318]]\n"
     ]
    }
   ],
   "source": [
    "# Results of prediction model\n",
    "\n",
    "ypred = mymodel.predict(pred_paded)\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2158f3b9-bdcb-49c9-832b-18c7b463d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Rounding off the prediction score\n",
    "\n",
    "import numpy as np\n",
    "print(np.around(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8675e659-a467-4fca-a3ea-f2498db796f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 9, 27, 7, 29, 3], [10, 7, 28, 27], [5, 10, 7, 28], [10, 9, 17, 28, 19, 11, 7]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the prediction model\n",
    "\n",
    "topredict =['yes i love going to parties', 'Can we go outside', 'Where can we go', 'yes i will go for a picnic']\n",
    "\n",
    "test_vocab = 30\n",
    "encod_test= [one_hot(d, test_vocab) for d in topredict]\n",
    "print(encod_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f3fd625-fe90-430c-953a-a36f3f4fa284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 10  9 27  7 29  3]\n",
      " [ 0  0  0 10  7 28 27]\n",
      " [ 0  0  0  5 10  7 28]\n",
      " [10  9 17 28 19 11  7]]\n"
     ]
    }
   ],
   "source": [
    "# Padding the test model\n",
    "\n",
    "max_length = 7\n",
    "test_paded = pad_sequences(encod_test, maxlen= max_length, padding='pre')\n",
    "print(test_paded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6763be38-cebc-4b74-9031-5bb564a7a556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "# Result of test model\n",
    "\n",
    "predictions = mymodel.predict(test_paded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78c47977-6e5c-4598-a128-87db05ac6ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Final result after rounding off\n",
    "\n",
    "import numpy as np\n",
    "print(np.around(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcef79d-2155-43ea-8edc-6900bf48637b",
   "metadata": {},
   "source": [
    "## <U> Conclusion: </U> \n",
    "Based on the outcomes of our prediction model, we can see that our model categorised questions as 0 and answers as 1. However, it's worth noting that \"Where\" was categorised as a question, despite the fact that we only trained our model with can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241136a1-c5b2-40a5-942c-fc4634a7a56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
